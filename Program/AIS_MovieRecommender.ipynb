{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load MovieLens dataset\n",
    "def load_movielens_data():\n",
    "    df = pd.read_csv('/home/korisnik/Desktop/AIS-MovieRecomenderSystem/Data/ml-1m/ratings.csv', sep=':')\n",
    "    \n",
    "    # Clean column names by stripping leading/trailing whitespace\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Print column names to verify\n",
    "    print(\"Columns in the DataFrame:\", df.columns)\n",
    "    \n",
    "    # Pivot the DataFrame, replace 'userId' with the correct column name if necessary\n",
    "    df = df.pivot(index='userId', columns='movieId', values='ratings').fillna(0)\n",
    "    df_sample = df.sample(frac=0.1)\n",
    "    \n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate affinity (similarity) between antibodies and antigens\n",
    "def calculate_affinity(user_profiles, user_ratings):\n",
    "    return cosine_similarity(user_profiles, user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise_mutation(clones, mean=0, std=0.1):\n",
    "    noise = np.random.normal(mean, std, clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)\n",
    "\n",
    "def adaptive_mutation(clones, affinities, base_mutation_rate=0.1, scaling_factor=0.5):\n",
    "    # Higher mutation for lower affinity\n",
    "    mutation_rate = base_mutation_rate * (1 - scaling_factor * affinities)\n",
    "    noise = np.random.normal(0, mutation_rate[:, np.newaxis], clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)\n",
    "\n",
    "def crossover_mutation(clones, crossover_rate=0.5):\n",
    "    num_clones = clones.shape[0]\n",
    "    for i in range(0, num_clones, 2):\n",
    "        if np.random.rand() < crossover_rate:\n",
    "            # Select a crossover point\n",
    "            crossover_point = np.random.randint(1, clones.shape[1])\n",
    "            # Swap segments between two clones\n",
    "            clones[i, crossover_point:], clones[i+1, crossover_point:] = clones[i+1, crossover_point:], clones[i, crossover_point:]\n",
    "    return clones\n",
    "\n",
    "def differential_mutation(clones, mutation_factor=0.8):\n",
    "    num_clones = clones.shape[0]\n",
    "    for i in range(num_clones):\n",
    "        indices = np.random.choice(num_clones, 3, replace=False)\n",
    "        diff = mutation_factor * (clones[indices[1]] - clones[indices[2]])\n",
    "        clones[i] = np.clip(clones[indices[0]] + diff, 0, 1)\n",
    "    return clones\n",
    "\n",
    "def simulated_annealing_mutation(clones, initial_temp=1.0, cooling_rate=0.99, iteration=1):\n",
    "    temp = initial_temp * (cooling_rate ** iteration)\n",
    "    noise = np.random.normal(0, temp, clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)\n",
    "\n",
    "def elite_mutation(clones, affinities, elite_fraction=0.1):\n",
    "    elite_size = int(elite_fraction * len(clones))\n",
    "    elite_indices = np.argsort(affinities)[-elite_size:]\n",
    "    mutated_clones = np.copy(clones)\n",
    "    \n",
    "    # Apply mutation to non-elite clones\n",
    "    non_elite_indices = np.setdiff1d(np.arange(len(clones)), elite_indices)\n",
    "    mutated_clones[non_elite_indices] = gaussian_noise_mutation(clones[non_elite_indices])\n",
    "    \n",
    "    return mutated_clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clonal_selection_and_advanced_mutation(affinity, user_profiles, iteration, mutation_rate=0.1):\n",
    "    best_indices = np.argsort(affinity.sum(axis=1))[-int(len(user_profiles) * 0.1):]\n",
    "    best_profiles = user_profiles[best_indices]\n",
    "    \n",
    "    clones = np.repeat(best_profiles, repeats=5, axis=0)\n",
    "    \n",
    "    # Apply advanced mutations\n",
    "    clones = gaussian_noise_mutation(clones)\n",
    "    clones = adaptive_mutation(clones, affinity)\n",
    "    clones = crossover_mutation(clones)\n",
    "    clones = differential_mutation(clones)\n",
    "    clones = simulated_annealing_mutation(clones, iteration=iteration)\n",
    "    clones = elite_mutation(clones, affinity)\n",
    "    \n",
    "    return clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clonal_selection_and_mutation(affinity, user_profiles, mutation_rate=0.1):\n",
    "    # Select best-performing antibodies\n",
    "    best_indices = np.argsort(affinity.sum(axis=1))[-int(len(user_profiles) * 0.1):]\n",
    "    best_profiles = user_profiles[best_indices]\n",
    "    \n",
    "    # Clone and mutate\n",
    "    clones = np.repeat(best_profiles, repeats=5, axis=0)\n",
    "    mutation = np.random.normal(0, mutation_rate, clones.shape)\n",
    "    clones = clones + mutation\n",
    "    \n",
    "    return clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIS-based recommender system\n",
    "def ais_recommender_system(data, num_generations=10, mutation_rate=0.1):\n",
    "    user_profiles = np.random.rand(data.shape[0], data.shape[1])  # Initialize antibodies\n",
    "    \n",
    "    for _ in range(num_generations):\n",
    "        affinity = calculate_affinity(user_profiles, data)\n",
    "        user_profiles = clonal_selection_and_mutation(affinity, user_profiles, mutation_rate)\n",
    "        \n",
    "        # Convergence check (optional): if no improvement, stop early\n",
    "    \n",
    "    # Generate recommendations based on final user_profiles\n",
    "    recommendations = np.dot(user_profiles, data.T)\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for unevaluated movies for a fresh user\n",
    "def predict_ratings_for_unevaluated(user_profile, data, known_ratings_indices):\n",
    "    # Calculate similarity between the new user profile and all item profiles\n",
    "    item_similarity = cosine_similarity([user_profile], data)[0]\n",
    "    \n",
    "    # Predict ratings for all items\n",
    "    predicted_ratings = np.dot(item_similarity, data) / np.sum(np.abs(item_similarity))\n",
    "    \n",
    "    # Mask the items that the user has already rated\n",
    "    #predicted_ratings[known_ratings_indices] = -np.inf  # Set known ratings to -inf to exclude them\n",
    "    \n",
    "    return predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the recommender system on the test population\n",
    "def evaluate_recommender_system(test_data, train_data):\n",
    "    mse_scores = []\n",
    "    \n",
    "    for user_id in range(test_data.shape[0]):\n",
    "        user_profile = test_data.iloc[user_id].values\n",
    "        known_ratings_indices = np.where(user_profile > 0)[0]\n",
    "        \n",
    "        # If the user has some ratings in the test set, predict ratings for the rest\n",
    "        if len(known_ratings_indices) > 0:\n",
    "            predicted_ratings = predict_ratings_for_unevaluated(user_profile, train_data, known_ratings_indices)\n",
    "            \n",
    "            # Only evaluate the predicted ratings for the movies that were actually rated in the test set\n",
    "            true_ratings = user_profile[user_profile > 0]\n",
    "            predicted_ratings_filtered = predicted_ratings[user_profile > 0]\n",
    "            \n",
    "            # Calculate MSE for this user\n",
    "            mse = mean_squared_error(true_ratings, predicted_ratings_filtered)\n",
    "            mse_scores.append(mse)\n",
    "    \n",
    "    # Return the average MSE over all users in the test set\n",
    "    return np.mean(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision@K for a single user\n",
    "def precision_at_k_evaluations(actual_ratings, predicted_ratings, k):\n",
    "    # Get indices of the top K predictions\n",
    "    top_k_indices = np.argsort(predicted_ratings)[-k:][::-1]\n",
    "    \n",
    "    # Count how many of these top K items are in the actual liked items\n",
    "    relevant_items = np.sum(actual_ratings[top_k_indices] > 0)\n",
    "    \n",
    "    # Calculate Precision@K\n",
    "    return relevant_items / k\n",
    "\n",
    "# Compute Precision@K for a single user\n",
    "def precision_at_k_selection(actual_ratings, predicted_ratings, k):\n",
    "    # Get indices of the top K predictions\n",
    "    top_k_indices = np.argsort(predicted_ratings)[-k:][::-1]\n",
    "    \n",
    "    # Count how many of these top K items are in the actual liked items\n",
    "    relevant_items = np.argsort(actual_ratings)[-k:][::-1]\n",
    "\n",
    "    relevant_and_recommended = np.intersect1d(top_k_indices, relevant_items)\n",
    "    precision = len(relevant_and_recommended) / k\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the recommender system using Precision@K on the test population\n",
    "def evaluate_precision_at_k(test_data, train_data, k=10, use_selection=True):\n",
    "    precision_scores = []\n",
    "    \n",
    "    for user_id in range(test_data.shape[0]):\n",
    "        user_profile = test_data.iloc[user_id].values\n",
    "        known_ratings_indices = np.where(user_profile > 0)[0]\n",
    "        \n",
    "        # If the user has some ratings in the test set, predict ratings for the rest\n",
    "        if len(known_ratings_indices) > 0:\n",
    "            predicted_ratings = predict_ratings_for_unevaluated(user_profile, train_data, known_ratings_indices)\n",
    "            \n",
    "            # Calculate Precision@K for this user\n",
    "            if use_selection:\n",
    "                precision_k = precision_at_k_selection(user_profile, predicted_ratings, k)\n",
    "            else:\n",
    "                precision_k = precision_at_k_evaluations(user_profile, predicted_ratings, k)\n",
    "            precision_scores.append(precision_k)\n",
    "    \n",
    "    # Return the average Precision@K over all users in the test set\n",
    "    return np.mean(precision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the DataFrame: Index(['userId', 'movieId', 'ratings'], dtype='object')\n",
      "Mean Squared Error on the test population (ratings): 9.132717855148945\n",
      "Precision - average evaluation of top-10 recomended movies: 0.5429752066115703\n",
      "Mean Squared Error on the top-10 recomended movies: 0.12148760330578513\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Main function to tie everything together\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and split the data\n",
    "    data = load_movielens_data()\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the AIS-based recommender on the training set\n",
    "    recommendations = ais_recommender_system(train_data)\n",
    "    \n",
    "    # Evaluate the recommender system on the test population\n",
    "    average_mse = evaluate_recommender_system(test_data, train_data)\n",
    "    print(f\"Mean Squared Error on the test population (ratings): {average_mse}\")\n",
    "    \n",
    "    average_precision_k = evaluate_precision_at_k(test_data, train_data, k=10, use_selection=False)\n",
    "    print(f\"Precision - average evaluation of top-10 recomended movies: {average_precision_k}\")\n",
    "\n",
    "    average_precision_k = evaluate_precision_at_k(test_data, train_data, k=10)\n",
    "    print(f\"Mean Squared Error on the top-10 recomended movies: {average_precision_k}\")\n",
    "    \n",
    "    print(f\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
