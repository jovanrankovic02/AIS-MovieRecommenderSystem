{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load MovieLens dataset\n",
    "def load_movielens_data():\n",
    "    df = pd.read_csv('/home/korisnik/Desktop/AIS-MovieRecomenderSystem/Data/ml-1m/ratings.csv')  # Replace with actual path\n",
    "    df = df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate affinity (similarity) between antibodies and antigens\n",
    "def calculate_affinity(user_profiles, user_ratings):\n",
    "    return cosine_similarity(user_profiles, user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonal selection and mutation\n",
    "def clonal_selection_and_mutation(affinity, user_profiles, mutation_rate=0.1):\n",
    "    # Select best-performing antibodies\n",
    "    best_indices = np.argsort(affinity.sum(axis=1))[-int(len(user_profiles) * 0.1):]\n",
    "    best_profiles = user_profiles[best_indices]\n",
    "    \n",
    "    # Clone and mutate\n",
    "    clones = np.repeat(best_profiles, repeats=5, axis=0)\n",
    "    mutation = np.random.normal(0, mutation_rate, clones.shape)\n",
    "    clones = clones + mutation\n",
    "    \n",
    "    return clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIS-based recommender system\n",
    "def ais_recommender_system(data, num_generations=10, mutation_rate=0.1):\n",
    "    user_profiles = np.random.rand(data.shape[0], data.shape[1])  # Initialize antibodies\n",
    "    \n",
    "    for _ in range(num_generations):\n",
    "        affinity = calculate_affinity(user_profiles, data)\n",
    "        user_profiles = clonal_selection_and_mutation(affinity, user_profiles, mutation_rate)\n",
    "        \n",
    "        # Convergence check (optional): if no improvement, stop early\n",
    "    \n",
    "    # Generate recommendations based on final user_profiles\n",
    "    recommendations = np.dot(user_profiles, data.T)\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise_mutation(clones, mean=0, std=0.1):\n",
    "    noise = np.random.normal(mean, std, clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)  # Ensure values are within valid range\n",
    "\n",
    "def adaptive_mutation(clones, affinities, base_mutation_rate=0.1, scaling_factor=0.5):\n",
    "    # Higher mutation for lower affinity\n",
    "    mutation_rate = base_mutation_rate * (1 - scaling_factor * affinities)\n",
    "    noise = np.random.normal(0, mutation_rate[:, np.newaxis], clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)\n",
    "\n",
    "def crossover_mutation(clones, crossover_rate=0.5):\n",
    "    num_clones = clones.shape[0]\n",
    "    for i in range(0, num_clones, 2):\n",
    "        if np.random.rand() < crossover_rate:\n",
    "            # Select a crossover point\n",
    "            crossover_point = np.random.randint(1, clones.shape[1])\n",
    "            # Swap segments between two clones\n",
    "            clones[i, crossover_point:], clones[i+1, crossover_point:] = clones[i+1, crossover_point:], clones[i, crossover_point:]\n",
    "    return clones\n",
    "\n",
    "def differential_mutation(clones, mutation_factor=0.8):\n",
    "    num_clones = clones.shape[0]\n",
    "    for i in range(num_clones):\n",
    "        indices = np.random.choice(num_clones, 3, replace=False)\n",
    "        diff = mutation_factor * (clones[indices[1]] - clones[indices[2]])\n",
    "        clones[i] = np.clip(clones[indices[0]] + diff, 0, 1)\n",
    "    return clones\n",
    "\n",
    "def simulated_annealing_mutation(clones, initial_temp=1.0, cooling_rate=0.99, iteration=1):\n",
    "    temp = initial_temp * (cooling_rate ** iteration)\n",
    "    noise = np.random.normal(0, temp, clones.shape)\n",
    "    mutated_clones = clones + noise\n",
    "    return np.clip(mutated_clones, 0, 1)\n",
    "\n",
    "def elite_mutation(clones, affinities, elite_fraction=0.1):\n",
    "    elite_size = int(elite_fraction * len(clones))\n",
    "    elite_indices = np.argsort(affinities)[-elite_size:]\n",
    "    mutated_clones = np.copy(clones)\n",
    "    \n",
    "    # Apply mutation to non-elite clones\n",
    "    non_elite_indices = np.setdiff1d(np.arange(len(clones)), elite_indices)\n",
    "    mutated_clones[non_elite_indices] = gaussian_noise_mutation(clones[non_elite_indices])\n",
    "    \n",
    "    return mutated_clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clonal_selection_and_advanced_mutation(affinity, user_profiles, iteration, mutation_rate=0.1):\n",
    "    best_indices = np.argsort(affinity.sum(axis=1))[-int(len(user_profiles) * 0.1):]\n",
    "    best_profiles = user_profiles[best_indices]\n",
    "    \n",
    "    clones = np.repeat(best_profiles, repeats=5, axis=0)\n",
    "    \n",
    "    # Apply advanced mutations\n",
    "    clones = gaussian_noise_mutation(clones)\n",
    "    clones = adaptive_mutation(clones, affinity)\n",
    "    clones = crossover_mutation(clones)\n",
    "    clones = differential_mutation(clones)\n",
    "    clones = simulated_annealing_mutation(clones, iteration=iteration)\n",
    "    clones = elite_mutation(clones, affinity)\n",
    "    \n",
    "    return clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommendations, test_data, k=10):\n",
    "    num_users = test_data.shape[0]\n",
    "    precision_scores = []\n",
    "    \n",
    "    for user_id in range(num_users):\n",
    "        # Get the top K recommended movie indices\n",
    "        recommended_indices = recommendations[user_id].argsort()[::-1][:k]\n",
    "        # Get the actual top K movie indices based on the test data\n",
    "        relevant_indices = test_data[user_id].argsort()[::-1][:k]\n",
    "        \n",
    "        # Compute the intersection of recommended and relevant movies\n",
    "        relevant_and_recommended = np.intersect1d(recommended_indices, relevant_indices)\n",
    "        precision = len(relevant_and_recommended) / k\n",
    "        precision_scores.append(precision)\n",
    "    \n",
    "    return np.mean(precision_scores)\n",
    "\n",
    "def compute_rmse(predictions, ground_truth):\n",
    "    # Flatten both matrices to compare the corresponding predicted and actual ratings\n",
    "    predictions = predictions[test_data.nonzero()].flatten()\n",
    "    ground_truth = test_data[test_data.nonzero()].flatten()\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(ground_truth, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_movielens_data()\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    recommendations = ais_recommender_system(train_data)\n",
    "    \n",
    "    # Evaluate the recommendations (e.g., using RMSE or Precision@K)\n",
    "    # Placeholder: print recommendations for a specific user\n",
    "    user_id = 0\n",
    "    print(\"Recommended movies for user:\", recommendations[user_id].argsort()[::-1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================\n",
    "# Hypermparameter fitting code below\n",
    "#==================================================================\n",
    "def objective_function(hyperparameters, train_data, test_data):\n",
    "    population_size = hyperparameters['population_size']\n",
    "    cloning_rate = hyperparameters['cloning_rate']\n",
    "    mutation_rate = hyperparameters['mutation_rate']\n",
    "    num_generations = hyperparameters['num_generations']\n",
    "    crossover_rate = hyperparameters['crossover_rate']\n",
    "    differential_factor = hyperparameters['differential_factor']\n",
    "    cooling_rate = hyperparameters['cooling_rate']\n",
    "    \n",
    "    # Train the AIS-based recommender system with these hyperparameters\n",
    "    recommendations = ais_recommender_system(train_data, \n",
    "                                             population_size=population_size, \n",
    "                                             cloning_rate=cloning_rate, \n",
    "                                             mutation_rate=mutation_rate, \n",
    "                                             num_generations=num_generations, \n",
    "                                             crossover_rate=crossover_rate, \n",
    "                                             differential_factor=differential_factor, \n",
    "                                             cooling_rate=cooling_rate)\n",
    "    \n",
    "    # Evaluate the system on the test set\n",
    "\n",
    "    score = precision_at_k(recommendations, test_data)\n",
    "    \n",
    "    return score  # Typically, lower is better if you're minimizing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "param_space = {\n",
    "    'population_size': [50, 100, 200],\n",
    "    'cloning_rate': [0.1, 0.3, 0.5],\n",
    "    'mutation_rate': [0.05, 0.1, 0.2],\n",
    "    'num_generations': [10, 20, 50],\n",
    "    'crossover_rate': [0.3, 0.5, 0.7],\n",
    "    'differential_factor': [0.5, 0.8, 1.0],\n",
    "    'cooling_rate': [0.95, 0.99, 0.999]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "num_iterations = 50\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Randomly sample hyperparameters\n",
    "    hyperparameters = {key: np.random.choice(values) for key, values in param_space.items()}\n",
    "    \n",
    "    # Evaluate the objective function\n",
    "    score = objective_function(hyperparameters, train_data, test_data)\n",
    "    \n",
    "    # Update the best score and parameters if the current score is better\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = hyperparameters\n",
    "\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
